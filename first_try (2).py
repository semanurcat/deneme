# -*- coding: utf-8 -*-
"""first_try.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1swyaMPK10ozvA8-bG4_AIXNhlT97ffj_
"""

from google.colab import drive
drive.mount('/content/drive')

# Import PyTorch
import torch
from torch import nn

# Import torchvision
import torchvision
from torchvision import datasets
from torchvision import transforms
from torchvision.transforms import ToTensor

# Import matplotlib for visualization
import matplotlib.pyplot as plt

print(torch.__version__)
print(torchvision.__version__)

import cv2
import os

dosya_yolu = '/content/drive/MyDrive/data'

dosya_isimleri = os.listdir(dosya_yolu)

for dosya in dosya_isimleri:

  if dosya.endswith('.pgm'):

    resim_yolu = dosya_yolu + '/' + dosya

    resim = cv2.imread(resim_yolu)

    # cv2_imshow(resim)

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/data/info.csv')

df

from torchvision import transforms
from PIL import Image

transform = transforms.Compose([
  transforms.ToTensor()
])


class MyDataset(datasets.VisionDataset):

  def __init__(self, root=dosya_yolu,train=True,
               transform=None, target_transform=None,download=False):
     self.root = dosya_yolu
     self.train = train
     self.img_names = resim
     self.labels = df
     self.transform = transform
     self.download = download


  def __len__(self):
    return len(self.img_names)

  def __getitem__(self, index):

    img_path = str(self.root) + "/" + str(self.img_names[index])

    img = Image.open(img_path).convert('RGB')

    if self.transform:
      img = self.transform(img)

    return img, self.labels[index]

"""train_data = MyDataset(
    root="data", #where to download data to?
    train=True, # do we want the training dataset?
    download=True, # do we want to download yes/no?
    transform=ToTensor(), # how do we want to transform the data?
    target_transform=None # how do we want to transform the labels/targets?
)
test_data = MyDataset(
    root="data", #where to download data to?
    train=False, # do we want the training dataset?
    download=True, # do we want to download yes/no?
    transform=ToTensor(), # how do we want to transform the data?
    target_transform=None # how do we want to transform the labels/targets?
)

len(train_data), len(test_data)
"""



"""
from sklearn.model_selection import train_test_split
import numpy as np

# Veri kümesinin tamamını yükleme
root_path = '/content/drive/MyDrive/data'  # Veri kümesinin bulunduğu dizin
train_data = MyDataset(
    root=root_path,
    train=True,
    download=True,
    transform=ToTensor(),
    target_transform=None
)
test_data = MyDataset(
    root=root_path,
    train=False,
    download=True,
    transform=ToTensor(),
    target_transform=None
)

# Eğitim ve test veri kümelerini oluşturma
train_size = int(0.8 * len(train_data))
test_size = len(train_data) - train_size

# Verileri NumPy dizilerine dönüştürme
all_x = np.empty((len(train_data), *train_data[0][0].shape), dtype=np.float32)
all_y = np.empty((len(train_data)), dtype=np.int64)

for i, (x, y) in enumerate(train_data):
    all_x[i] = x
    all_y[i] = y

# Veri kümesini eğitim ve doğrulama alt kümelerine bölmek
X_train, X_val, y_train, y_val = train_test_split(all_x, all_y, test_size=test_size, random_state=42)

# Veri kümesinin boyutlarını kontrol etme
len(X_train), len(X_val), len(test_data)
"""

from torch.utils.data import DataLoader, Subset
from sklearn.model_selection import train_test_split

# Önce MyDataset sınıfı ile veri kümesini oluşturun
my_dataset = MyDataset(root="data", train=True, download=True, transform=ToTensor())

# Veri kümesini eğitim ve test setlerine bölmek için train_test_split'i kullanın
train_indices, test_indices = train_test_split(list(range(len(my_dataset))), test_size=0.2, random_state=42)

# Eğitim ve test veri kümelerini oluşturun
train_dataset = Subset(my_dataset, train_indices)
test_dataset = Subset(my_dataset, test_indices)

# Dataloader'ları oluşturun (batch_size'i ve diğer parametreleri ayarlayabilirsiniz)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Şimdi train_loader ve test_loader ile modelinizi eğitebilirsiniz

len(train_dataset), len(test_dataset)

import matplotlib.pyplot as plt
image, label = train_dataset[0]
print(f"Image shape: {image.shape}")
plt.imshow(image.squeeze())
plt.title(label);
# image















